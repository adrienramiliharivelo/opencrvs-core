# 3.3.1 Provision your server nodes with SSH access

1. Using your hosting provider, setup 1, 3 or 5 Ubuntu server nodes with an additional backup server node should you require this option. Take note of all generated IP addresses and server hostnames.  \
   \
   Minimum requirements for each server:\
   8 GB Memory (preferrably 16 GB) / 320 GB Disk / Ubuntu 20.04 (LTS) x64\

2. Decide which of your IP addresses will be the **manager server node.** This server will be the manager in the Docker Swarm and the main server used to control load balancing.\

3.  Add your users GIT SSH keys to all nodes, and ensure that you take a note of each server's **hostname.** This is a handy command to copy any SSH keys you use on Git into a server's .ssh/authorized\_keys file.\


    ```
    curl https://github.com/<git-user>.keys >> ~/.ssh/authorized_keys
    ```


4.  For production deployments of 3 or 5 servers, or where you are provisioning a server backup, ensure the **manager server node** can ssh into all the other worker and backup nodes.\
    \
    SSH into **manager server node** and create an ssh key. Press Enter for defaults and no passphrase\


    ```
    ssh-keygen
    ```

    \
    Print the key for copying: \


    ```
    cat ~/.ssh/id_rsa.pub
    ```

    \
    Copy the key and exit the manager node.\
    \
    SSH into the 2 or 4 worker nodes to add the key into the .ssh/authorised\_keys for all nodes\


    ```
    echo "<manager-node-public-key>" >> ~/.ssh/authorized_keys
    ```

    \
    SSH into the **manager server node**, and confirm that you can SSH into all nodes from inside the manager node.\


    If you are setting up a backup server, ensure that the **manager server node** can ssh into that too. SSH into the backup node to add the key into its .ssh/authorised\_keys file.\


    You are now ready to exit all nodes and run the Ansible command from your local environment to install the required dependencies on the servers.
